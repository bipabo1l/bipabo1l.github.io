<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bipabo1l&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/f12afe463f30521d5f4d7321a2b377d6</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-01-17T10:24:04.084Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Bipabo1l</name>
    <email>bipabo1l@csoio.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>scrapy-cluster分布式url爬虫集群</title>
    <link href="http://yoursite.com/2018/01/12/scrapy-cluster%E5%88%86%E5%B8%83%E5%BC%8Furl%E7%88%AC%E8%99%AB%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2018/01/12/scrapy-cluster分布式url爬虫集群/</id>
    <published>2018-01-12T13:28:52.000Z</published>
    <updated>2018-01-17T10:24:04.084Z</updated>
    
    <content type="html"><![CDATA[<h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><p>一个企业如何做到足够的安全？相信很多措施是必不可少的，其中收集足够多的公司资产和有一个足够强大的黑盒扫描爬虫是十分必要的，做好了这两条我们便知道我们的企业有什么需要保护的，并且能够保证这些需要保护的东西在黑客视野下难以侵入。但企业中大多数的资产是domain和ip，我们如果能够针对每个domain,为黑盒扫描器提供更全的url信息，会使我们的防御更全面。最近笔者就干了一件类似的事，大致说来通过基于Scrapy Cluster的框架将爬取出我们需要的包信息，从Kafka中过滤出url数据，然后通过url相似性去重对url去重，最终将结果存入mongodb持久化存储并建立http server进行API数据输出。与本文涉及的代码已经上传到笔者的github:<code>https://github.com/bipabo1l/scrapycluster_url_processing</code>。url去重部分参考了dean的urlclean golang项目。</p><a id="more"></a><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>架构图如下，画的较丑见谅；<br><img src="http://ovnsp3bhk.bkt.clouddn.com/11.png" alt=""></p><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>我们拥有的资源是三台内网机器，在本文将以127.0.0.1，127.0.0.2，127.0.0.3表示。</p><h2 id="scrapy-cluster集群搭建"><a href="#scrapy-cluster集群搭建" class="headerlink" title="scrapy-cluster集群搭建"></a>scrapy-cluster集群搭建</h2><p>先通过cdh将三台集群自动下载与配置好kafka+zookeeper环境。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/12.png" alt=""></p><p>利用cdh安装两大组件后，测试kafka+zookeeper集群搭建是否成功<br>127.0.0.1上创建topic.</p><pre><code>kafka-topics --create --zookeeper 127.0.0.2:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><p><img src="http://ovnsp3bhk.bkt.clouddn.com/13.png" alt=""><br>127.0.0.2上查看名为test的topic</p><pre><code>kafka-topics --describe --zookeeper 127.0.0.1:2181 --topic test</code></pre><p><img src="http://ovnsp3bhk.bkt.clouddn.com/14.png" alt=""><br>查看集群中所有的 topic 列表</p><pre><code>kafka-topics --list --zookeeper 127.0.0.1:2181</code></pre><p><img src="http://ovnsp3bhk.bkt.clouddn.com/15.png" alt=""><br>利用此 topic 来生产和消费</p><pre><code>kafka-console-producer --broker-list 127.0.0.1:9092 --topic testkafka-console-consumer --zookeeper 127.0.0.1:2181 --topic test --from-beginning</code></pre><p>发现consumer可以时时消费producer生产出的数据，证明集群搭建成功。<br>在三台机器上搭建redis，python2.7环境。<br>redis：</p><pre><code>scp redis-2.8.17.tar.gz root@127.0.0.1:/export/Datatar -zvxf redis-2.8.17.tar.gzcd redis-2.8.17makecp redis-server /usr/local/bin/cp redis-cli /usr/local/bin/cp redis-check-aof /usr/local/bin/cp redis-check-dump /usr/local/bin/cp redis-benchmark /usr/local/bin/</code></pre><p>vim redis.conf 将daemonize 由no设置为yes</p><p>随后安装scrapy cluster集群。</p><pre><code>wget https://github.com/istresearch/scrapy-cluster/archive/v1.1.tar.gzpip install -r requirements.txt</code></pre><p>如果没有pip，先yum安装pip安装时可能遇到错误 Errno 14 Couldn’t resolve host<br>解决方式：</p><pre><code>vim /etc/resolv.conf加入 nameserver 8.8.8.8</code></pre><p>pip安装requirements.txt内所有的包时，可能会遇到些许报错：<br>No package ‘libffi’ found<br>解决方式：yum install libffi-devel<br>c/_cffi_backend.c:2:20: 致命错误： Python.h：没有那个文件或目录， 解决如下：</p><pre><code>yum install libxslt-devel</code></pre><p>解决方式：sudo yum install python-devel<br><img src="http://ovnsp3bhk.bkt.clouddn.com/16.png" alt=""><br>都安装成功后，cd /export/Data/scrapy-cluster-1.1<br>离线运行单元测试,以确保一切似乎正常,表示依赖安装成功。<br>./run_offline_tests.sh<br><img src="http://ovnsp3bhk.bkt.clouddn.com/17.png" alt=""><br>证明安装成功。<br>在三个组件中新建localsettings.py文件并设置kafka，redis，zookeeper的相关配置以确保通信</p><pre><code>cd kafka-monitor/vim localsettings.pyREDIS_HOST = &apos;127.0.0.1&apos;KAFKA_HOSTS = &apos;127.0.0.1:9092,127.0.0.2:9092,127.0.0.3:9092&apos;</code></pre><p>配置好后分别测试集群<br><img src="http://ovnsp3bhk.bkt.clouddn.com/18.png" alt=""><br><img src="http://ovnsp3bhk.bkt.clouddn.com/19.png" alt=""></p><h2 id="scrapy-cluster集群工作"><a href="#scrapy-cluster集群工作" class="headerlink" title="scrapy-cluster集群工作"></a>scrapy-cluster集群工作</h2><p>1.启动每台机器的kafka，zookeeper，redis.<br>2.python kafka_monitor.py run<br>3.scrapy runspider crawling/spiders/link_spider.py<br>4.python kafkadump.py dump -t demo.crawled_firehose<br>5.python kafkadump.py dump -t demo.outbound_firehose<br>6.python redis_monitor.py</p><p>需要并行执行这些脚本，建议多窗口运行，比如利用tmux开启新窗口。<br>python kafka_monitor.py run<br><img src="http://ovnsp3bhk.bkt.clouddn.com/20.png" alt=""><br>yum isntall tmux<br>tmux new -s python_kafka_run<br>tmux ls：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/21.png" alt=""><br>查看当前所有topic：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/22.png" alt=""><br>进行url爬虫：<br>这里需要多看scrapy-cluster api文档<a href="http://scrapy-cluster.readthedocs.io/en/latest/topics/kafka-monitor/api.html#crawl-api" target="_blank" rel="external">http://scrapy-cluster.readthedocs.io/en/latest/topics/kafka-monitor/api.html#crawl-api</a>.<br>假设当前需要爬取网址：php0.net</p><pre><code>[root@172 kafka-monitor]# python kafka_monitor.py feed &apos;{&quot;url&quot;: &quot;http://php0.net/&quot;, &quot;appid&quot;:&quot;php0appid3&quot;, &quot;crawlid&quot;:&quot;php0crawlid3&quot;, &quot;maxdepth&quot;:3, &quot;allowed_domains&quot;:[&quot;php0.net&quot;]}&apos;2018-01-10 17:40:10,678 [kafka-monitor] INFO: Feeding JSON into demo.incoming{&quot;url&quot;: &quot;http://php0.net/&quot;, &quot;maxdepth&quot;: 3, &quot;allowed_domains&quot;: [&quot;php0.net&quot;], &quot;crawlid&quot;: &quot;php0crawlid3&quot;, &quot;appid&quot;: &quot;php0appid3&quot;}2018-01-10 17:40:10,690 [kafka-monitor] INFO: Successfully fed item to Kafka</code></pre><p>随后我们启动dump监听redis返回的结果：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/23.png" alt=""><br>可以时时监听到完整的json数据，格式如下：</p><pre><code>{ &quot;body&quot;: &quot;&lt;body string omitted&gt;&quot;, &quot;crawlid&quot;: &quot;ABC123&quot;, &quot;response_url&quot;: &quot;http://istresearch.com&quot;, &quot;url&quot;: &quot;http://istresearch.com&quot;, &quot;status_code&quot;: 200, &quot;status_msg&quot;: &quot;OK&quot;, &quot;appid&quot;: &quot;testapp&quot;, &quot;links&quot;: [], &quot;request_headers&quot;: { &quot;Accept-Language&quot;: &quot;en&quot;, &quot;Accept-Encoding&quot;: &quot;gzip,deflate&quot;, &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&quot;, &quot;User-Agent&quot;: &quot;Scrapy/1.0.3 (+http://scrapy.org)&quot; }, &quot;attrs&quot;: null, &quot;timestamp&quot;: &quot;2016-01-05T20:14:54.653703&quot; }</code></pre><p>利用python脚本获取爬取到的url数据，吐到mongodb里，因为这里我们不需要body数据，只需要url数据和其对应的扫描id，我们在127.0.0.3中安装mongodb，由于网络限制将其27017端口改成443，内网办公网段方可访问。<br>kafka_data_tomongo.py:</p><pre><code>from pykafka import KafkaClientfrom scapy.all import *import timeimport loggingfrom pymongo import MongoClientlogging.getLogger(&quot;pykafka&quot;).addHandler(logging.StreamHandler())logging.getLogger(&quot;pykafka&quot;).setLevel(logging.DEBUG)sys_config = {&quot;database&quot;: {&quot;db_name&quot;: &quot;url_pool&quot;,&quot;db_host&quot;: &quot;mongodb://127.0.0.3:443/&quot;}}client = MongoClient(sys_config[&apos;database&apos;][&apos;db_host&apos;])db_connect = client[sys_config[&apos;database&apos;][&apos;db_name&apos;]]client = KafkaClient(zookeeper_hosts =&quot;127.0.0.1:2181,127.0.0.2:2181,127.0.0.3:2181&quot;)topic = client.topics[&apos;demo.crawled_firehose&apos;]if __name__==&quot;__main__&quot;:     consumer = topic.get_balanced_consumer(consumer_group=&apos;test_group&apos;,auto_commit_enable=True)     regex = &apos;response_url\&quot;: \&quot;(.*?)\&quot;,&apos;    regex2 = &apos;appid\&quot;: \&quot;(.*?)\&quot;}&apos;    domain_list = []    url = &quot;&quot;    appid = &quot;&quot;    for message in consumer:        print message.value    for m in re.findall(regex, message.value):        url = m        domain_list.append(url)        break    for k in re.findall(regex2, message.value):        appid = k        break    try:        db_connect.urls.save({&quot;url&quot;: url, &quot;appid&quot;: appid})        print &quot;mongodb insert success&quot;    except ValueError, e:        print &quot;mongodb insert Error&quot;    print domain_list</code></pre><p>可以看到短时间内爬取到了1260个url<br><img src="http://ovnsp3bhk.bkt.clouddn.com/24.png" alt=""><br><img src="http://ovnsp3bhk.bkt.clouddn.com/25.png" alt=""><br>然而这些真是我们想要的吗？太多类似的url，需要我们相似性去重。</p><h2 id="url去重"><a href="#url去重" class="headerlink" title="url去重"></a>url去重</h2><p>url去重这里借鉴了路哥urlclean golang版本的思路，对每个url先根据参数排序，然后生成正则，将正则存入redis中的正则规则表中，最后比对每个url的正则，如果发现了新的就存入redis中的url表中。<br>关键代码如下：</p><pre><code>def UrlSortAndCleanKey(url_str):    new_url = url_str    url1 = urlparse.urlsplit(url_str)    key_list = {}    key_list2 = []    value_list = []    l = url1.query.split(&quot;&amp;&quot;)    for k in l:        kk = k.split(&quot;=&quot;)        if len(kk) &gt; 1:            key_list[kk[0]] = kk[1]            value_list.append(kk[1])    for p in key_list:        if p not in del_key_list:            key_list2.append(p)    key_query_str = &quot;&quot;    for pp in sorted(key_list.keys()):        key_query_str += &quot;&amp;&quot; + pp + &quot;=&quot; + key_list[pp]    if url1.fragment != &quot;&quot;:        key_query_str += &quot;#&quot; + url1.fragment    query_str = &quot;&quot;    if key_query_str != &quot;&quot;:        query_str = &quot;?&quot; + key_query_str[1:]    new_url = url1.scheme + &apos;://&apos; + url1.netloc + url1.path + query_str    return new_urldef SimRepeatRemove(url_str):    is_exists = False    rex_symbol_list = [&quot;$&quot;, &quot;(&quot;, &quot;)&quot;, &quot;*&quot;, &quot;+&quot;, &quot;.&quot;, &quot;[&quot;, &quot;]&quot;, &quot;?&quot;, &quot;\\&quot;, &quot;^&quot;, &quot;{&quot;, &quot;}&quot;, &quot;|&quot;, &quot;/&quot;]    result = client.lrange(SIM_RULE_KEY,0,-1)    for p in result:        matchObj = re.search(p,url_str, re.M|re.I)        if matchObj:            is_exists = True            break    if is_exists == False:        for rex in rex_symbol_list:            url_str = url_str.replace(rex,&apos;\\&apos; + rex)            url_str = url_str.replace(r&apos;\\&apos;,&apos;\\&apos;)        url_str = &apos;^&apos; + url_str + &apos;$&apos;        rule = re.sub(&apos;\d+&apos;,&apos;(\d+)&apos; , url_str, count=0, flags=0)        client.lrem(SIM_RULE_KEY,rule,num=0)        client.lpush(SIM_RULE_KEY,rule)    return is_existsdef UrlClean(urls,url):    t = int(time.time())    url = UrlSortAndCleanKey(url)    url_hash = md5(url)    is_exists = client.hexists(URL_HASH_KEY,url_hash)    if is_exists == False:        if SimRepeatRemove(url) == False:            client.hset(URL_HASH_KEY,url_hash,t)            client.lpush(URL_KEY,url)            return 1        else:            #print url            return -1    else:        print url        return 0</code></pre><h2 id="最终脚本"><a href="#最终脚本" class="headerlink" title="最终脚本"></a>最终脚本</h2><p>最终脚本如下：</p><pre><code># coding=utf-8import hashlibimport redisimport urlparseimport timeimport refrom pykafka import KafkaClientfrom scapy.all import *import timeimport loggingfrom pymongo import MongoClientimport webEyelogging.getLogger(&quot;pykafka&quot;).addHandler(logging.StreamHandler())logging.getLogger(&quot;pykafka&quot;).setLevel(logging.DEBUG)URL_KEY = &quot;urls&quot;URL_HASH_KEY = &quot;url_hash_key&quot;SIM_RULE_KEY = &quot;sim_rule_key&quot;client_redis = redis.Redis(host=&apos;127.0.0.1&apos;,port=6379,db=8)del_key_list = [&quot;_&quot;]sys_config = {    &quot;database&quot;: {        &quot;db_name&quot;: &quot;url_pool&quot;,        &quot;db_host&quot;: &quot;mongodb://172.20.214.71:443/&quot;    }}client_mongo = MongoClient(sys_config[&apos;database&apos;][&apos;db_host&apos;])db_connect = client_mongo[sys_config[&apos;database&apos;][&apos;db_name&apos;]]client = KafkaClient(zookeeper_hosts =&quot;172.20.214.66:2181,172.20.214.69:2181,172.20.214.71:2181&quot;)topic = client.topics[&apos;demo.crawled_firehose&apos;]def md5(strs):    m1 = hashlib.md5()    m1.update(strs)    return m1.hexdigest()def UrlSortAndCleanKey(url_str):    new_url = url_str    url1 = urlparse.urlsplit(url_str)    key_list = {}    key_list2 = []    value_list = []    l = url1.query.split(&quot;&amp;&quot;)    for k in l:        kk = k.split(&quot;=&quot;)        if len(kk) &gt; 1:            key_list[kk[0]] = kk[1]            value_list.append(kk[1])    for p in key_list:        if p not in del_key_list:            key_list2.append(p)    key_query_str = &quot;&quot;    for pp in sorted(key_list.keys()):        key_query_str += &quot;&amp;&quot; + pp + &quot;=&quot; + key_list[pp]    if url1.fragment != &quot;&quot;:        key_query_str += &quot;#&quot; + url1.fragment    query_str = &quot;&quot;    if key_query_str != &quot;&quot;:        query_str = &quot;?&quot; + key_query_str[1:]    new_url = url1.scheme + &apos;://&apos; + url1.netloc + url1.path + query_str    return new_urldef SimRepeatRemove(url_str):    is_exists = False    rex_symbol_list = [&quot;$&quot;, &quot;(&quot;, &quot;)&quot;, &quot;*&quot;, &quot;+&quot;, &quot;.&quot;, &quot;[&quot;, &quot;]&quot;, &quot;?&quot;, &quot;\\&quot;, &quot;^&quot;, &quot;{&quot;, &quot;}&quot;, &quot;|&quot;, &quot;/&quot;]    result = client_redis.lrange(SIM_RULE_KEY,0,-1)    for p in result:        matchObj = re.search(p,url_str, re.M|re.I)        if matchObj:            is_exists = True            break    if is_exists == False:        for rex in rex_symbol_list:            url_str = url_str.replace(rex,&apos;\\&apos; + rex)            url_str = url_str.replace(r&apos;\\&apos;,&apos;\\&apos;)        url_str = &apos;^&apos; + url_str + &apos;$&apos;        rule = re.sub(&apos;\d+&apos;,&apos;(\d+)&apos; , url_str, count=0, flags=0)        client_redis.lrem(SIM_RULE_KEY,rule,num=0)        client_redis.lpush(SIM_RULE_KEY,rule)    return is_existsdef UrlClean(urls,url):    t = int(time.time())    url = UrlSortAndCleanKey(url)    url_hash = md5(url)    is_exists = client_redis.hexists(URL_HASH_KEY,url_hash)    if is_exists == False:        if SimRepeatRemove(url) == False:            client_redis.hset(URL_HASH_KEY,url_hash,t)            client_redis.lpush(URL_KEY,url)            return 1        else:            #print url            return -1    else:        print url        return 0if __name__==&quot;__main__&quot;:      consumer = topic.get_balanced_consumer(consumer_group=&apos;test_group&apos;,auto_commit_enable=True)     regex = &apos;response_url\&quot;: \&quot;(.*?)\&quot;,&apos;    regex2 = &apos;appid\&quot;: \&quot;(.*?)\&quot;}&apos;    domain_list = []    url = &quot;&quot;    appid = &quot;&quot;    for message in consumer:        print message.value        for m in re.findall(regex, message.value):            url = m            domain_list.append(url)            break        for k in re.findall(regex2, message.value):            appid = k            break        urls_list = db_connect.urls.find({&quot;appid&quot;: appid}).distinct(&apos;url&apos;)        webEye_res = webEye.WebEye(url)        webEye_res.run()        webEye_info = list(webEye_res.cms_list)        if UrlClean(urls_list,url) != -1:            #去重后的url库            try:                db_connect.urls.save({&quot;url&quot;: url, &quot;appid&quot;: appid, &quot;fingerprint&quot;:webEye_info})                print &quot;mongodb insert success&quot;            except ValueError, e:                print &quot;mongodb insert Error&quot;        print &quot;----------------------------------------------------------------------------------------------&quot;</code></pre><h2 id="Http服务器搭建"><a href="#Http服务器搭建" class="headerlink" title="Http服务器搭建"></a>Http服务器搭建</h2><p>Http服务器直接使用了Flask框架，提供Reastful API以供其他调用。代码非常简单，如下：</p><pre><code>@app.route(&apos;/scrapyresult&apos;)def scrapy_url():    appid = request.args.get(&apos;appid&apos;, None)    condition = {}    if appid and appid != &apos;&apos;:        condition[&apos;appid&apos;] = appid    model = db_connect.urls.find(condition,{&quot;_id&quot;:0})    data = []    for _ in model:        data.append(_)    totalcount = model.count()    if data:        return ajaxReturn(data, totalcount,&apos;get result success&apos;, 1,)    else:        return ajaxReturn(None,totalcount, &quot;result is null&quot;, -1)</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文的架构还有优化的思路，可以在kafka到redis，redis到mongodb的数据流转中优化性能。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://gitee.com/lujunjian/UrlClean" target="_blank" rel="external">https://gitee.com/lujunjian/UrlClean</a><br><a href="http://blog.csdn.net/Tilyp/article/details/56298954" target="_blank" rel="external">http://blog.csdn.net/Tilyp/article/details/56298954</a><br><a href="https://scrapy-cluster.readthedocs.io/en/latest/" target="_blank" rel="external">https://scrapy-cluster.readthedocs.io/en/latest/</a><br>多谢Dean、Mr hao、Tanglion</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;主题&quot;&gt;&lt;a href=&quot;#主题&quot; class=&quot;headerlink&quot; title=&quot;主题&quot;&gt;&lt;/a&gt;主题&lt;/h2&gt;&lt;p&gt;一个企业如何做到足够的安全？相信很多措施是必不可少的，其中收集足够多的公司资产和有一个足够强大的黑盒扫描爬虫是十分必要的，做好了这两条我们便知道我们的企业有什么需要保护的，并且能够保证这些需要保护的东西在黑客视野下难以侵入。但企业中大多数的资产是domain和ip，我们如果能够针对每个domain,为黑盒扫描器提供更全的url信息，会使我们的防御更全面。最近笔者就干了一件类似的事，大致说来通过基于Scrapy Cluster的框架将爬取出我们需要的包信息，从Kafka中过滤出url数据，然后通过url相似性去重对url去重，最终将结果存入mongodb持久化存储并建立http server进行API数据输出。与本文涉及的代码已经上传到笔者的github:&lt;code&gt;https://github.com/bipabo1l/scrapycluster_url_processing&lt;/code&gt;。url去重部分参考了dean的urlclean golang项目。&lt;/p&gt;
    
    </summary>
    
      <category term="安全研发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/"/>
    
    
      <category term="Scrapy Cluster" scheme="http://yoursite.com/tags/Scrapy-Cluster/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Kafka" scheme="http://yoursite.com/tags/Kafka/"/>
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>集群监控之golang socket双向通信</title>
    <link href="http://yoursite.com/2017/11/07/%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E4%B9%8Bgolang-socket%E5%8F%8C%E5%90%91%E9%80%9A%E4%BF%A1/"/>
    <id>http://yoursite.com/2017/11/07/集群监控之golang-socket双向通信/</id>
    <published>2017-11-07T09:26:35.000Z</published>
    <updated>2017-11-07T09:53:44.384Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>本例中，40台机器构建成一个集群，完成对IP存活的扫描以及调用nmap扫描ip段，通过golang socket将一台Server机器与30余台Agent机器建立双向通信机制，支持断线重连，已完成Server端对Agent的扫描情况、是否在工作的监控，通过Beego+Layui研发web页面以管理。</p><h2 id="具体细节"><a href="#具体细节" class="headerlink" title="具体细节"></a>具体细节</h2><p>Server端本地监听自己的8848端口，供与client端通信，同时启动自己的8849端口作为web端口，接受来自web端的请求，client端会尝试与Server端通信，一旦建立连接，会以全双工的方式，建立双向通信管道。在一个conn连接下server与client互联，互相发送请求与状态。<br>代码地址：<br>    <a href="https://github.com/bipabo1l/TyrantSocket" target="_blank" rel="external">https://github.com/bipabo1l/TyrantSocket</a><br>关键代码如下：<br>Server端：<br>    package main</p><pre><code>import (    &quot;GoRadar/core&quot;    &quot;GoRadar/lib&quot;    &quot;encoding/json&quot;    &quot;fmt&quot;    &quot;log&quot;    &quot;net&quot;    &quot;os&quot;    &quot;os/exec&quot;    &quot;path/filepath&quot;    &quot;strings&quot;    &quot;sync&quot;    &quot;time&quot;    &quot;github.com/benmanns/goworker&quot;    &quot;gopkg.in/mgo.v2/bson&quot;    &quot;github.com/bipabo1l/TyrantSocket/protocol&quot;    &quot;net/http&quot;    )    var waitgroup sync.WaitGroup    var mIPRangePool lib.MongoDriver    var is_private int    var scan_mode_param string    var is_limit_scan_rate bool    var IPRange1 string    type IPRangePool struct {        IPRange string `bson:&quot;ip_range&quot;`    }    //记录所有Agent    var clientArr = make(map[string]net.Conn)    var ipRangeArr = make(map[string]string)    type AgentMsg struct {        Session int64        IP      string        Message string        Status  string    }    //定义CheckError方法，避免写太多到 if err!=nil    func CheckError(err error) {        if err != nil {            fmt.Fprintf(os.Stderr, &quot;Fatal error:%s&quot;, err.Error())            os.Exit(1)        }    }    //自定义log    func Log(v ...interface{}) {        log.Println(v...)    }    var ch1 = make(chan int, 1)    func init() {        cfg := lib.NewConfigUtil(&quot;&quot;)        redis_host, _ := cfg.GetString(&quot;redis_default&quot;, &quot;host&quot;)        redis_port, _ := cfg.GetString(&quot;redis_default&quot;, &quot;port&quot;)        redis_pass, _ := cfg.GetString(&quot;redis_default&quot;, &quot;pass&quot;)        redis_db, _ := cfg.GetString(&quot;redis_default&quot;, &quot;db&quot;)        var dsn_addr string        if redis_pass != &quot;&quot; {            dsn_addr = fmt.Sprintf(&quot;redis://:%s@%s:%s/%s&quot;, redis_pass, redis_host, redis_port, redis_db)        } else {            dsn_addr = fmt.Sprintf(&quot;redis://%s:%s/%s&quot;, redis_host, redis_port, redis_db)        }        // 初始化        settings := goworker.WorkerSettings{            URI:            dsn_addr,            Connections:    100,            Queues:         []string{&quot;scannerQueue&quot;, &quot;ScanPortQuene&quot;},            UseNumber:      true,            ExitOnComplete: false,            Concurrency:    2,            Namespace:      &quot;goradar:&quot;,            Interval:       5.0,        }        goworker.SetSettings(settings)        // 初始化数据库连接        mIPRangePool = lib.MongoDriver{TableName: &quot;ip_range_pool&quot;}        err := mIPRangePool.Init()        if err != nil {            fmt.Println(&quot;INIT MONGODB ERRPR:&quot; + err.Error())        }        //initialize deploy mode        deploy, _ := cfg.GetString(&quot;server_default&quot;, &quot;deploy&quot;)        if deploy == &quot;inner&quot; {            is_private = 1            scan_mode_param = &quot;q&quot;            is_limit_scan_rate = true        } else if deploy == &quot;outer&quot; {            is_private = 2            scan_mode_param = &quot;d&quot;            is_limit_scan_rate = false        } else {            fmt.Println(&quot;config server_defaul-&gt;deploy error: only &apos;inner&apos; or &apos;outer&apos; allowed&quot;)            os.Exit(1)        }    }    func main() {        // 加入守护进程机制        if os.Getppid() != 1 {            //判断当其是否是子进程，当父进程return之后，子进程会被 系统1 号进程接管            filePath, _ := filepath.Abs(os.Args[0])            //将命令行参数中执行文件路径转换成可用路径            cmd := exec.Command(filePath)            //将其他命令传入生成出的进程            cmd.Stdin = os.Stdin            //给新进程设置文件描述符，可以重定向到文件中            cmd.Stdout = os.Stdout            cmd.Stderr = os.Stderr            //开始执行新进程，不等待新进程退出            cmd.Start()            return        }        //mode_param := flag.String(&quot;mode&quot;, &quot;q&quot;, &quot;for quick scan: -mode q , for detail scan -mode d ;default -mode q &quot;)        //if *mode_param != &quot;q&quot; &amp;&amp; *mode_param != &quot;d&quot; {        //    fmt.Println(&quot;for quick scan: -mode q , for detail scan -mode d ; default -mode q&quot;)        //    os.Exit(1)        //}        waitgroup.Add(3)        go ListenMsg()        // 清理昨天数据(5分钟)        go func() {            for {                timer1 := time.NewTimer(time.Minute * 5)                &lt;-timer1.C                cna := core.NewClearNotActivity()                cna.Clear()                fmt.Println(&quot;清理完成&quot;)            }        }()        // 添加任务(10分钟)        go func() {            // 首次运行            one_run := true            for {                if one_run == false {                    timer1 := time.NewTimer(time.Minute * 10)                    &lt;-timer1.C                }                // 添加扫描任务                IPRangePool := new([]IPRangePool)                ip_range_pool, err := mIPRangePool.NewTable()                if err == nil {                    // TODO 由于扫内网存活会造成大量Arp请求，目前暂时只扫描外网IP段                    ip_range_pool.Find(bson.M{&quot;is_private&quot;: is_private}).All(IPRangePool)                    for _, ip_range := range *IPRangePool {                        fmt.Println(&quot;添加一条存活探测任务:&quot; + ip_range.IPRange)                        // 不阻塞,增加扫描任务                        goworker.Enqueue(&amp;goworker.Job{                            Queue: &quot;ScanActivityQueue&quot;,                            Payload: goworker.Payload{                                Class: &quot;ScanActivityTask&quot;,                                Args:  []interface{}{string(ip_range.IPRange), is_limit_scan_rate},                            },                        })                    }                } else {                    fmt.Println(&quot;ERROR:&quot; + err.Error())                }                one_run = false            }        }()        // 添加端口扫描任务(5)        go func() {            // 首次运行            one_run := true            for {                if one_run == false {                    timer1 := time.NewTimer((time.Hour * 24) * 2)                    &lt;-timer1.C                }                // 添加扫描任务                IPRangePool := new([]IPRangePool)                ip_range_pool, err := mIPRangePool.NewTable()                if err == nil {                    // TODO 由于扫外网占用大量session表，目前暂时只扫描内网                    ip_range_pool.Find(bson.M{&quot;is_private&quot;: is_private}).All(IPRangePool)                    for _, ip_range := range *IPRangePool {                        fmt.Println(&quot;添加一条端口扫描任务:&quot; + ip_range.IPRange)                        // 不阻塞,增加扫描任务                        goworker.Enqueue(&amp;goworker.Job{                            Queue: &quot;ScanPortQuene&quot;,                            Payload: goworker.Payload{                                Class: &quot;ScanPortTask&quot;,                                Args:  []interface{}{string(ip_range.IPRange), scan_mode_param, is_limit_scan_rate},                            },                        })                    }                } else {                    fmt.Println(&quot;ERROR:&quot; + err.Error())                }                one_run = false            }        }()        waitgroup.Wait()        fmt.Println(&quot;添加任务完成&quot;)    }    ////自定义log    //func Log(v ...interface{}) {    //    //    log.Println(v...)    //}    func ListenMsg() {        server_listener, err := net.Listen(&quot;tcp&quot;, &quot;192.168.0.8:8848&quot;)        //server_listener, err := net.Listen(&quot;tcp&quot;, &quot;127.0.0.1:8848&quot;)        CheckError(err)        defer server_listener.Close()        Log(&quot;Waiting for clients connect&quot;)        go getConn()        for {            new_conn, err := server_listener.Accept()            clientIPList := strings.Split(new_conn.RemoteAddr().String(), &quot;:&quot;)            clientIP := new_conn.RemoteAddr().String()            if len(clientIPList) &gt; 0 {                clientIP = clientIPList[0]            }            log.Println(clientIP)            clientArr[clientIP] = new_conn            CheckError(err)            log.Println(new_conn.RemoteAddr().String() + &quot; 上线了&quot;)            go ServerMsgHandler(new_conn)        }    }    func getConn() {        http.HandleFunc(&quot;/&quot;, sayhelloName)        err := http.ListenAndServe(&quot;:8849&quot;, nil)        if err != nil {            log.Fatal(&quot;ListenAndServe: &quot;, err)        }    }    type IPList struct {        IPPort   string   `json:&quot;ipport&quot;`        ConnList net.Conn `json:&quot;netconn&quot;`    }    type IPListMap struct {        IPListMap []IPList    }    func sayhelloName(w http.ResponseWriter, r *http.Request) {        r.ParseForm()        key := &quot;&quot;        value := &quot;&quot;        sign := 0        for k, v := range r.Form {            if k != &quot;&quot; &amp;&amp; strings.Join(v, &quot;&quot;) != &quot;&quot; {                key = k                value = strings.Join(v, &quot;&quot;)            }        }        //监听8849端口判断批量getStatus动作        if key == &quot;key&quot; &amp;&amp; value == &quot;getstatus&quot; {            data, err := json.Marshal(clientArr)            if err != nil {                log.Println(err)                return            }            s := strings.Split(string(data[:]), &quot;,&quot;)            ll := &quot;&quot;            if len(s) &gt; 0 {                for _, w := range s {                    k := strings.Split(w, &quot;:&quot;)                    if len(k) &gt; 0 &amp;&amp; ll != &quot;&quot; {                        ll = ll + &quot;,&quot; + k[0]                        ll = strings.Replace(ll, &quot;{&quot;, &quot;&quot;, -1)                        ll = strings.Replace(ll, `&quot;`, &quot;&quot;, -1)                        ll = strings.Replace(ll, `}`, &quot;&quot;, -1)                    } else if len(k) &gt; 0 {                        ll = k[0]                        ll = strings.Replace(ll, &quot;{&quot;, &quot;&quot;, -1)                        ll = strings.Replace(ll, `&quot;`, &quot;&quot;, -1)                        ll = strings.Replace(ll, `}`, &quot;&quot;, -1)                    }                }            }            fmt.Fprintf(w, `{&quot;Agent&quot;:&quot;`+ll+`&quot;}`)        } else if key == &quot;key&quot; &amp;&amp; strings.Count(value, &quot;&quot;)-1 &gt;= 4 {            if protocol.Substr2(value, 0, 4) == &quot;stop&quot; {                sign = 1                ip := protocol.Substr2(value, 4, len(value))                log.Println(&quot;-----------------------------&quot;)                log.Println(clientArr)                findConn := clientArr[ip]                go StopClient(findConn)                fmt.Fprintf(w, &quot;1&quot;)            }            if strings.Count(value, &quot;&quot;)-1 &gt;= 5 &amp;&amp; sign == 0 {                if protocol.Substr2(value, 0, 5) == &quot;start&quot; {                    sign = 1                    ip := protocol.Substr2(value, 5, len(value))                    log.Println(&quot;-----------------------------&quot;)                    log.Println(clientArr)                    findConn := clientArr[ip]                    go BeginClient(findConn)                    fmt.Fprintf(w, &quot;1&quot;)                }            }            if strings.Count(value, &quot;&quot;)-1 &gt;= 10 &amp;&amp; sign == 0 {                if protocol.Substr2(value, 0, 10) == &quot;getiprange&quot; {                    log.Println(&quot;服务端请求当前扫描的IPRange&quot;)                    ip := protocol.Substr2(value, 10, len(value))                    log.Println(&quot;服务端接收到ip:&quot;)                    log.Println(ip)                    fmt.Println(clientArr)                    fmt.Println(ipRangeArr)                    if _, ok := clientArr[ip]; ok {                        go IPRangeClient(clientArr[ip])                    }                    if len(ipRangeArr) &gt; 0 {                        //by, err := json.Marshal(ipRangeArr)                        //if err != nil {                        //    log.Println(err)                        //}                        //fmt.Fprintf(w, string(by))                        if _, ok := ipRangeArr[ip]; ok {                            fmt.Fprintf(w, `{&quot;IPrange&quot;:&quot;`+ipRangeArr[ip]+`&quot;}`)                        }                    } else {                        fmt.Fprintf(w, `{&quot;IPrange&quot;:&quot;`+`&quot;}`)                    }                }            }        }    }    //服务端消息处理    func ServerMsgHandler(conn net.Conn) {        //存储被截断的数据        tmpbuf := make([]byte, 0)        buf := make([]byte, 1024)        defer conn.Close()        //接收解包        readchan := make(chan []byte, 16)        go ReadChan(readchan)        for {            //读取客户端发来的消息            n, err := conn.Read(buf)            if err != nil {                fmt.Println(&quot;connection close&quot;)                removeClient(conn)                conn.Close()                return            }            //解包            tmpbuf = protocol.Depack(append(tmpbuf, buf[:n]...))            //tmpbuf = buf            fmt.Println(&quot;client say:&quot;, string(tmpbuf))            //判断解析json            var agentmsg AgentMsg            json.Unmarshal([]byte(string(tmpbuf)), &amp;agentmsg)            Msg := tmpbuf            log.Println(agentmsg.Status)            if agentmsg.Status == &quot;STOPPED&quot; {                removeClient(conn)            }            if agentmsg.Status == &quot;IPRange&quot; {                log.Println(&quot;Agent.Sattus&quot;)                IPRange1 = agentmsg.Message                ipRangeArr[agentmsg.IP] = agentmsg.Message            }            //向客户端发送消息            go WriteMsgToClient(conn)            go func() {                if &lt;-ch1 == 2 {                    WriteMsgToClient2(conn)                }            }()            beatch := make(chan byte)            //心跳计时，默认30秒            go HeartBeat(conn, beatch, 30)            //检测每次Client是否有数据传来            go HeartChanHandler(Msg, beatch)        }    }    //处理心跳,根据HeartChanHandler判断Client是否在设定时间内发来信息    func HeartBeat(conn net.Conn, heartChan chan byte, timeout int) {        select {        case hc := &lt;-heartChan:            Log(&quot;&lt;-heartChan:&quot;, string(hc))            conn.SetDeadline(time.Now().Add(time.Duration(timeout) * time.Second))            break        case &lt;-time.After(time.Second * 30):            Log(&quot;timeout&quot;)            conn.Close()        }    }    //服务端向客户端发送消息    func WriteMsgToClient(conn net.Conn) {        log.Println(conn.RemoteAddr())        talk := &quot;RUN&quot;        smsg := protocol.Enpack([]byte(talk))        conn.Write(smsg)    }    func WriteMsgToClient2(conn net.Conn) {        talk := &quot;GETSTATUS&quot;        smsg := protocol.Enpack([]byte(talk))        conn.Write(smsg)    }    //Server表示不想跟您通信咯    func StopClient(conn net.Conn) {        talk := &quot;STOP&quot;        smsg := protocol.Enpack([]byte(talk))        conn.Write(smsg)    }    //Server表示不想跟您通信咯    func BeginClient(conn net.Conn) {        talk := &quot;BEGIN&quot;        smsg := protocol.Enpack([]byte(talk))        conn.Write(smsg)    }    func IPRangeClient(conn net.Conn) {        talk := &quot;IPRANGE&quot;        smsg := protocol.Enpack([]byte(talk))        conn.Write(smsg)    }    //处理心跳channel    func HeartChanHandler(n []byte, beatch chan byte) {        for _, v := range n {            beatch &lt;- v            log.Println(v)        }        close(beatch)    }    //从channell中读取数据    func ReadChan(readchan chan []byte) {        for {            select {            case data := &lt;-readchan:                Log(string(data))            }        }    }    func removeClient(new_conn net.Conn) {        log.Println(clientArr)        log.Println(new_conn.RemoteAddr().String() + &quot; 已经阵亡&quot;)        clientIPList := strings.Split(new_conn.RemoteAddr().String(), &quot;:&quot;)        clientIP := new_conn.RemoteAddr().String()        if len(clientIPList) &gt; 0 {            clientIP = clientIPList[0]        }        log.Println(clientIP)        delete(clientArr, clientIP)        log.Println(&quot;delete close conn&quot;)        log.Println(clientArr)        return    }</code></pre><p>client端：</p><pre><code>package mainimport (    &quot;GoRadar/core&quot;    &quot;GoRadar/lib&quot;    &quot;errors&quot;    &quot;fmt&quot;    &quot;io&quot;    &quot;io/ioutil&quot;    &quot;log&quot;    &quot;net&quot;    &quot;net/http&quot;    &quot;os&quot;    &quot;os/exec&quot;    &quot;path/filepath&quot;    &quot;runtime&quot;    &quot;strconv&quot;    &quot;time&quot;    &quot;github.com/benmanns/goworker&quot;    &quot;github.com/levigross/grequests&quot;    &quot;github.com/bipabo1l/TyrantSocket/protocol&quot;)//ch1 为-1时，与server端停止通信var chSign = make(chan int, 1)//var IPrange = make([]string, 0, 100)//var IPPortrange = make([]string, 0, 100)var IPRange = &quot;&quot;var IPPortrange = &quot;&quot;// 扫描func ScanActivityTask(queue string, args ...interface{}) error {    fmt.Println(&quot;调用队列:&quot; + queue)    ip_range := args[0].(string)    //IPrange = append(IPrange, ip_range)    IPRange = ip_range    is_limit_scan_rate := args[1].(bool)    sa := core.NewScanActivity()    sa.Scanner(ip_range, is_limit_scan_rate)    return nil}func ScanPortTask(queue string, args ...interface{}) error {    fmt.Println(&quot;调用队列:&quot; + queue)    ip_range := args[0].(string)    //IPPortrange = append(IPPortrange, ip_range)    IPPortrange = ip_range    scan_mode := args[1].(string)    is_limit_scan_rate := args[2].(bool)    sa := core.NewScanPort()    sa.Scan(ip_range, scan_mode, is_limit_scan_rate)    return nil}var (    version      = &quot;1.0.6&quot;    download_url = &quot;&quot;)func Version_validate(c chan string) bool {    resp, err := grequests.Get(&quot;http://43.226.164.114/version.txt&quot;, nil)    // You can modify the request by passing an optional RequestOptions struct    if err != nil {        fmt.Println(&quot;Validate version error: Unable to make request &quot;)        return false    } else {        new_version := resp.String()[0:5]        fmt.Println(&quot;new_version:&quot; + new_version)        fmt.Println(&quot;version:&quot; + version)        if version &lt; new_version {            os_name := runtime.GOOS            if os_name == &quot;linux&quot; {                download_url = &quot;http://43.226.164.114/linux/&quot; + new_version            } else if os_name == &quot;windows&quot; {                download_url = &quot;http://43.226.164.114/windows/&quot; + new_version            }            download, _ := Download_new_agent(download_url, os_name)            if download == true {                c &lt;- &quot;new&quot;                fmt.Println(&quot;New agent version found !&quot;)                return true            } else {                c &lt;- &quot;old&quot;                return false            }        } else {            return false        }    }}func Download_new_agent(url string, os_name string) (bool, error) {    res, err := http.Get(url)    if err != nil {        return false, err    }    var (        file_name string    )    if os_name == &quot;windows&quot; {        file_name = &quot;Agent.exe&quot;    } else if os_name == &quot;linux&quot; {        file_name = &quot;Agent&quot;    } else {        file_name = &quot;Agent&quot;    }    cmd := exec.Command(&quot;rm&quot;, &quot;-rf&quot;, file_name)    cmd.Run()    f, err := os.Create(file_name)    if err != nil {        return false, err    }    _, er := io.Copy(f, res.Body)    if er != nil {        return false, er    }    if os_name == &quot;linux&quot; {        cmdd := exec.Command(&quot;chmod&quot;, &quot;+x&quot;, file_name)        cmdd.Run()    }    res.Body.Close()    f.Close()    return true, er}func Restart_process() {    filePath, _ := filepath.Abs(os.Args[0])    cmd := exec.Command(filePath)    cmd.Stdout = os.Stdout    cmd.Stderr = os.Stderr    err := cmd.Start()    if err != nil {        log.Fatalf(&quot;GracefulRestart: Failed to launch, error: %v&quot;, err)    }}func init() {    cfg := lib.NewConfigUtil(&quot;&quot;)    redis_host, _ := cfg.GetString(&quot;redis_default&quot;, &quot;host&quot;)    redis_port, _ := cfg.GetString(&quot;redis_default&quot;, &quot;port&quot;)    redis_pass, _ := cfg.GetString(&quot;redis_default&quot;, &quot;pass&quot;)    redis_db, _ := cfg.GetString(&quot;redis_default&quot;, &quot;db&quot;)    var dsn_addr string    if redis_pass != &quot;&quot; {        dsn_addr = fmt.Sprintf(&quot;redis://:%s@%s:%s/%s&quot;, redis_pass, redis_host, redis_port, redis_db)    } else {        dsn_addr = fmt.Sprintf(&quot;redis://%s:%s/%s&quot;, redis_host, redis_port, redis_db)    }    settings := goworker.WorkerSettings{        URI:            dsn_addr,        Connections:    100,        Queues:         []string{&quot;ScanActivityQueue&quot;, &quot;ScanPortQuene&quot;},        UseNumber:      true,        ExitOnComplete: false,        Concurrency:    50,        Namespace:      &quot;goradar:&quot;,        Interval:       5.0,    }    goworker.SetSettings(settings)    //read scan option    activeswitch, _ := cfg.GetString(&quot;agent_default&quot;, &quot;scanactivity&quot;)    portswitch, _ := cfg.GetString(&quot;agent_default&quot;, &quot;scanport&quot;)    if activeswitch == &quot;yes&quot; {        goworker.Register(&quot;ScanActivityTask&quot;, ScanActivityTask)        fmt.Println(&quot;Start active scan !&quot;)    } else if activeswitch == &quot;no&quot; {        fmt.Println(&quot;Doesn&apos;t start active scan !&quot;)    } else {        fmt.Println(&quot;Error: config anget-&gt;scanactivity param error, only &apos;yes&apos; or &apos;no&apos; allowed&quot;)    }    if portswitch == &quot;yes&quot; {        goworker.Register(&quot;ScanPortTask&quot;, ScanPortTask)        fmt.Println(&quot;Start ports scan !&quot;)    } else if portswitch == &quot;no&quot; {        fmt.Println(&quot;Doesn&apos;t start ports scan !&quot;)    } else {        fmt.Println(&quot;Error: Config anget-&gt;scanport param error,only &apos;yes&apos; or &apos;no&apos; allowed&quot;)    }}func main() {    // 加入守护进程机制    if os.Getppid() != 1 {        //判断当其是否是子进程，当父进程return之后，子进程会被 系统1 号进程接管        filePath, _ := filepath.Abs(os.Args[0])        //将命令行参数中执行文件路径转换成可用路径        cmd := exec.Command(filePath)        //将其他命令传入生成出的进程        cmd.Stdin = os.Stdin        //给新进程设置文件描述符，可以重定向到文件中        cmd.Stdout = os.Stdout        cmd.Stderr = os.Stderr        //开始执行新进程，不等待新进程退出        cmd.Start()        return    }    signals := make(chan string)    go func() {        for {            Version_validate(signals)            time.Sleep(1 * time.Minute)        }    }()    go func() {        for {            log.Println(&quot;GOWoker Running&quot;)            err := goworker.Work()            if err != nil {                fmt.Println(&quot;Error:&quot;, err)            }        }    }()    go func() {        sendMsgToServer()    }()    for {        select {        case signal := &lt;-signals:            if signal == &quot;new&quot; {                Restart_process()                return            }        case &lt;-time.After(time.Second * 10):            fmt.Println(&quot;timeout, check again...&quot;)            continue        }    }}func sendMsgToServer() {    //动态传入服务端IP和端口号    service := &quot;192.168.0.8:8848&quot;    //service := &quot;127.0.0.1:8848&quot;    tcpAddr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, service)    CheckError(err)    for {        conn, err := net.DialTCP(&quot;tcp&quot;, nil, tcpAddr)        if err != nil {            fmt.Fprintf(os.Stderr, &quot;Fatal error:%s&quot;, err.Error())        } else {            defer conn.Close()            //连接服务器端成功            doWork(conn)        }        time.Sleep(3 * time.Second)    }}//定义CheckError方法，避免写太多到 if err!=nilfunc CheckError(err error) {    if err != nil {        fmt.Fprintf(os.Stderr, &quot;Fatal error:%s&quot;, err.Error())        os.Exit(1)    }}//解决断线重连问题func doWork(conn net.Conn) error {    ch := make(chan int, 100)    ticker := time.NewTicker(time.Second)    defer ticker.Stop()    for {        select {        case stat := &lt;-ch:            if stat == 2 {                return errors.New(&quot;None Msg&quot;)            }        case &lt;-ticker.C:            ch &lt;- 1            go ClientMsgHandler(conn, ch)            go ReadMsg(conn, ch)        case &lt;-time.After(time.Second * 2):            defer conn.Close()            fmt.Println(&quot;timeout&quot;)        }    }    return nil}//客户端消息处理func ClientMsgHandler(conn net.Conn, ch chan int) {    &lt;-ch    //获取当前时间    //msg := &quot;+++++++++++++++++++++++++++++++++++++&quot;    SendMsg(conn, &quot;rrrrr&quot;)    go ReadMsg(conn, ch)}func GetSession() string {    gs1 := time.Now().Unix()    gs2 := strconv.FormatInt(gs1, 10)    return gs2}//接收服务端发来的消息func ReadMsg(conn net.Conn, ch chan int) {    &lt;-ch    //存储被截断的数据    tmpbuf := make([]byte, 0)    buf := make([]byte, 1024)    //将信息解包    n, _ := conn.Read(buf)    tmpbuf = protocol.Depack(append(tmpbuf, buf[:n]...))    msg := string(tmpbuf)    fmt.Println(&quot;server say:&quot;, msg)    if len(msg) == 0 {        //服务端无返回信息        ch &lt;- 2    } else {        //接收到了服务器端发来的非空包，证明已经和服务器连接成功        if msg == &quot;RUN&quot; {            log.Println(&quot;收到服务器命令：发送Running包&quot;)            go func() {                SendMsg(conn, msg)                time.Sleep(time.Second * 2)            }()        } else if msg == &quot;GETSTATUS&quot; {            //服务器端想知道当前在没在工作            log.Println(&quot;Server端请求了解本Agent状态&quot;)            go SendRunMsg(conn, msg)        } else if msg == &quot;STOP&quot; {            //服务器让当前agent停止            log.Println(&quot;服务器让当前agent停止&quot;)            go func() {                StopRunMsg(conn, msg)                chSign &lt;- -1            }()            //go StopRunMsg(conn, msg)            //conn.Close()        } else if msg == &quot;BEGIN&quot; {            //服务器让当前agent停止            log.Println(&quot;服务器让当前agent重新连接&quot;)            go BeginRunMsg(conn, msg)            //conn.Close()        } else if msg == &quot;IPRANGE&quot; {            //服务器让当前agent停止            log.Println(&quot;服务器需要当前IPrange&quot;)            log.Println(IPRange)            go IPRangeMsg(conn, IPRange)        }    }}//向服务端发送消息func SendMsg(conn net.Conn, msg string) {    session := GetSession()    words := &quot;{\&quot;Session\&quot;:&quot; + session + &quot;,\&quot;IP\&quot;:\&quot;&quot; + GetMyIP() + &quot;\&quot;,\&quot;Message\&quot;:\&quot;&quot; + msg + &quot;\&quot;,\&quot;Status\&quot;:\&quot;&quot; + &quot;running&quot; + &quot;\&quot;}&quot;    //将信息封包    smsg := protocol.Enpack([]byte(words))    conn.Write(smsg)}//向服务端发送消息func SendRunMsg(conn net.Conn, msg string) {    session := GetSession()    words := &quot;{\&quot;Session\&quot;:&quot; + session + &quot;,\&quot;IP\&quot;:\&quot;&quot; + GetMyIP() + &quot;\&quot;,\&quot;Message\&quot;:\&quot;&quot; + msg + &quot;\&quot;,\&quot;Status\&quot;:\&quot;&quot; + &quot;IAMRunning&quot; + &quot;\&quot;}&quot;    //将信息封包    smsg := protocol.Enpack([]byte(words))    conn.Write(smsg)}//向服务端发送消息func StopRunMsg(conn net.Conn, msg string) {    session := GetSession()    words := &quot;{\&quot;Session\&quot;:&quot; + session + &quot;,\&quot;IP\&quot;:\&quot;&quot; + GetMyIP() + &quot;\&quot;,\&quot;Message\&quot;:\&quot;&quot; + msg + &quot;\&quot;,\&quot;Status\&quot;:\&quot;&quot; + &quot;STOPPED&quot; + &quot;\&quot;}&quot;    //将信息封包    smsg := protocol.Enpack([]byte(words))    conn.Write(smsg)    log.Println(&quot;----------------------------------&quot;)    conn.Close()}//向服务端发送消息func BeginRunMsg(conn net.Conn, msg string) {    session := GetSession()    words := &quot;{\&quot;Session\&quot;:&quot; + session + &quot;,\&quot;IP\&quot;:\&quot;&quot; + GetMyIP() + &quot;\&quot;,\&quot;Message\&quot;:\&quot;&quot; + msg + &quot;\&quot;,\&quot;Status\&quot;:\&quot;&quot; + &quot;Begin&quot; + &quot;\&quot;}&quot;    //将信息封包    smsg := protocol.Enpack([]byte(words))    conn.Write(smsg)    log.Println(&quot;----------------------------------&quot;)}func IPRangeMsg(conn net.Conn, msg string) {    session := GetSession()    words := &quot;{\&quot;Session\&quot;:&quot; + session + &quot;,\&quot;IP\&quot;:\&quot;&quot; + GetMyIP() + &quot;\&quot;,\&quot;Message\&quot;:\&quot;&quot; + msg + &quot;\&quot;,\&quot;Status\&quot;:\&quot;&quot; + &quot;IPRange&quot; + &quot;\&quot;}&quot;    //将信息封包    smsg := protocol.Enpack([]byte(words))    conn.Write(smsg)    log.Println(&quot;----------------------------------&quot;)}func GetMyIP() string {    addrs, err := net.InterfaceAddrs()    ip := &quot;&quot;    if err != nil {        fmt.Println(err)        os.Exit(1)    }    for _, address := range addrs {        // 检查ip地址判断是否回环地址        if ipnet, ok := address.(*net.IPNet); ok &amp;&amp; !ipnet.IP.IsLoopback() {            if ipnet.IP.To4() != nil {                ip = ipnet.IP.String()            }        }    }    return ip}func get_external() string {    resp, err := http.Get(&quot;http://myexternalip.com/raw&quot;)    if err != nil {        return &quot;&quot;    }    defer resp.Body.Close()    content, _ := ioutil.ReadAll(resp.Body)    log.Println(&quot;++++++++++++++++++++++++++++++++++++++++++++&quot;)    log.Println(string(content))    return string(content)}</code></pre><p>执行截图如下：<br>Server端：并行push任务到redis中并监听Agent情况<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-11-07_17-41-35.png" alt=""><br>Client端一方面读取Redis任务并开始工作，另一方面时时读取Server端的请求并执行工作<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-11-07_17-50-52.png" alt=""></p><p>web端展示页面如下：<br><img src="https://camo.githubusercontent.com/f56e9a31c1eae142b4bf7a1d26964be50c61d708/687474703a2f2f6f766e73703362686b2e626b742e636c6f7564646e2e636f6d2f536e6970617374655f323031372d31312d30375f31362d31352d31372e706e67" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;本例中，40台机器构建成一个集群，完成对IP存活的扫描以及调用nmap扫描ip段，通过golang socket将一台Server机器与30
      
    
    </summary>
    
      <category term="安全开发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Golang" scheme="http://yoursite.com/tags/Golang/"/>
    
      <category term="Beego" scheme="http://yoursite.com/tags/Beego/"/>
    
      <category term="Socket" scheme="http://yoursite.com/tags/Socket/"/>
    
  </entry>
  
  <entry>
    <title>记一次golang post xml时返回502错误码的问题</title>
    <link href="http://yoursite.com/2017/09/22/%E8%A7%A3%E5%86%B3golang-post-xml%E6%95%B0%E6%8D%AE%E5%B8%A6header%E6%97%B6502bad-gateway-%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2017/09/22/解决golang-post-xml数据带header时502bad-gateway-的问题/</id>
    <published>2017-09-22T03:28:58.000Z</published>
    <updated>2017-09-25T06:16:28.125Z</updated>
    
    <content type="html"><![CDATA[<h2 id="详情"><a href="#详情" class="headerlink" title="详情"></a>详情</h2><p>昨天由于项目需要，加入发送短信功能，首先测试了一下已存在的一个Python代码，原理比较简单，向一个接口发送一个http post请求，请求的数据为xml格式，同时请求会带一个header头，Key为Host信息。</p><a id="more"></a><p>Python代码如下：</p><pre><code># coding=utf-8import requestsimport cgidef send(phone, msg):    url = &apos;http://xxx.com/MoblMsgSender&apos;    headers = {        &apos;Host&apos;: &apos;xxx.com&apos;,    }    body = &apos;&lt;?xml version=&quot;1.0&quot; ?&gt;&lt;S:Envelope xmlns:S=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&gt;&lt;S:Header&gt;&lt;AuthenticationHeader xmlns=&quot;http://xxx.com/MoblMsgSender&quot;&gt;&lt;Token&gt;Tokenxxx==&lt;/Token&gt;&lt;/AuthenticationHeader&gt;&lt;/S:Header&gt;&lt;S:Body&gt;&lt;ns2:xxMmSender xmlns:ns2=&quot;http://xxx.com/&quot;&gt;&lt;arg0 xmlns=&quot;&quot;&gt;%s&lt;/arg0&gt;&lt;arg1 xmlns=&quot;&quot;&gt;%s&lt;/arg1&gt;&lt;arg2 xmlns=&quot;&quot;&gt;yunwei.alarm&lt;/arg2&gt;&lt;arg3 xmlns=&quot;&quot;&gt;&lt;/arg3&gt;&lt;/ns2:xxMmSender&gt;&lt;/S:Body&gt;&lt;/S:Envelope&gt;&apos; % (phone, cgi.escape(msg))    try:        r = requests.post(url, data=body, headers=headers)        if &apos;&lt;return&gt;true&lt;/return&gt;&apos; in r.content:            return True    except:        pass    return Falsesend(&quot;135xxxxxxx&quot;,&quot;testPython&quot;)</code></pre><p>果然成功收到了短信，证明接口调用成功。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-22_11-51-57.png" alt=""><br>于是我转化成golang代码：</p><pre><code>package mainimport (    &quot;bytes&quot;    &quot;crypto/tls&quot;    &quot;log&quot;    &quot;net/http&quot;    &quot;strings&quot;    &quot;time&quot;)func sendmessage(phone string, msg string) error {    uri := `http://xxx.com/MoblMsgSender`    //proxy, _ := url.Parse(&quot;http://127.0.0.1:8080&quot;)    tr := &amp;http.Transport{        //Proxy:           http.ProxyURL(proxy),        TLSClientConfig: &amp;tls.Config{InsecureSkipVerify: true},    }    client := &amp;http.Client{        Transport: tr,        Timeout:   time.Second * 5, //超时时间    }    body := `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;S:Envelope xmlns:S=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;&gt;&lt;S:Header&gt;&lt;AuthenticationHeader xmlns=&quot;http://mms.360buy.com/services/MoblMsgSender&quot;&gt;&lt;Token&gt;666a8EN3oIijHY+KjS+2mg==&lt;/Token&gt;&lt;/AuthenticationHeader&gt;&lt;/S:Header&gt;&lt;S:Body&gt;&lt;ns2:xxMmSender xmlns:ns2=&quot;http://xxx.com/&quot;&gt;&lt;arg0 xmlns=&quot;&quot;&gt;` + phone + `&lt;/arg0&gt;&lt;arg1 xmlns=&quot;&quot;&gt;` +     msg + `&lt;/arg1&gt;&lt;arg2 xmlns=&quot;&quot;&gt;yunwei.alarm&lt;/arg2&gt;&lt;arg3     xmlns=&quot;&quot;&gt;&lt;/arg3&gt;&lt;/ns2:xxMmSender&gt;&lt;/S:Body&gt;&lt;/    S:Envelope&gt;`    log.Println(strings.NewReader(body))    req, err := http.NewRequest(&quot;post&quot;, uri,     bytes.NewBuffer([]byte(body)))    if err != nil {        log.Println(err)        // handle error    }    req.Host = &quot;xxx.com&quot;    resp, err := client.Do(req)    if err != nil {        log.Println(err)    }    log.Println(resp)    //log.Println(respbody)    return err}func main() {    sendmessage(&quot;135xxxxxxx&quot;, &quot;testGolang&quot;)}</code></pre><p>然而我发现此请求并没有获取到短信，于是挂上代理进行抓包，发现其响应码为502.<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-22_14-08-08.png" alt=""><br>对比Python的正常请求：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-22_14-12-11.png" alt=""><br>发现是因为http.NewRequest()方法第一个参数options方法写错了，不能写成小写..</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;详情&quot;&gt;&lt;a href=&quot;#详情&quot; class=&quot;headerlink&quot; title=&quot;详情&quot;&gt;&lt;/a&gt;详情&lt;/h2&gt;&lt;p&gt;昨天由于项目需要，加入发送短信功能，首先测试了一下已存在的一个Python代码，原理比较简单，向一个接口发送一个http post请求，请求的数据为xml格式，同时请求会带一个header头，Key为Host信息。&lt;/p&gt;
    
    </summary>
    
      <category term="安全研发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Golang" scheme="http://yoursite.com/tags/Golang/"/>
    
      <category term="Xml" scheme="http://yoursite.com/tags/Xml/"/>
    
  </entry>
  
  <entry>
    <title>浅析Android中ZipEntry漏洞</title>
    <link href="http://yoursite.com/2017/09/10/%E6%B5%85%E6%9E%90Android%E4%B8%ADZipEntry%E6%BC%8F%E6%B4%9E/"/>
    <id>http://yoursite.com/2017/09/10/浅析Android中ZipEntry漏洞/</id>
    <published>2017-09-10T15:19:30.000Z</published>
    <updated>2017-09-10T16:09:49.013Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在Android APK加载时，通常情况下会请求各种资源，这其中就包括请求本地或者外部服务器的压缩文件。而由于zip格式压缩文件允许”../“的字符串，攻击者可以在APK加载时对应用本来想加载的文件进行“调虎离山”，将自己利用多个”../“生成的压缩文件替换原文件，这种情况下如果APK对这个zip文件解析不当，那么轻则导致文件覆盖，重则导致本地拒绝服务，甚至代码执行。</p><h2 id="漏洞原理"><a href="#漏洞原理" class="headerlink" title="漏洞原理"></a>漏洞原理</h2><p>这里以一个Apk为例说明，下图中，我反编译了一个APK，获取到了dex文件，利用dex2jar转换成了java中的jar文件并利用Java Decomplier进行读取。<br>定位到存在ZipEntry漏洞的地方，如下图所示：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/a3f3b1d75ac84edea68aa7298461cdc9.png" alt=""><br>可以发现代码的逻辑时调用zipEntry类中的getName()方法，获取到解压到的Zip文件中的自文件名称，但是并未进行任何的../过滤，从而允许了攻击者构造../的zip包进行攻击的可能，攻击者可以构造精心构造的zip包，在root过的手机中抓包，对包含zip的调用包进行篡改，将原zip包篡改成本地构造后的zip包，随后在本地查看文件管理器，可以发现攻击者指定的目录下的文件。<br>构造特定的zip包代码如下：（使用java编写）<br><img src="http://ovnsp3bhk.bkt.clouddn.com/1475713e45644a3283d617c93644fbf1.png" alt=""><br>执行后在zippoc根目录下可发现新生成的test.zip文件<br><img src="http://ovnsp3bhk.bkt.clouddn.com/5754c55d4c344a51aaf154ed0e83239b.png" alt=""><br><img src="http://ovnsp3bhk.bkt.clouddn.com/8f9dbd6785564952b741951744f0507a.png" alt=""><br>上传包中篡改该文件即可。<br>修复方案为在上传包中对文件名进行严格的校验，过滤”../“</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>该漏洞为移动安全漏洞中的低危或中危漏洞，其实不是很好利用，利用方式略微鸡肋但是影响却不小，但很多厂商并未对其进行过多的校验。笔者就发现了滴滴代驾司机客户端、斗鱼Android客户端、Wifi万能钥匙客户端等等均存在此漏洞并进行了报告。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-11_00-08-22.png" alt=""><br>该漏洞如果结合了其他漏洞也会产生较为严重的影响，希望厂商予以重视。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;在Android APK加载时，通常情况下会请求各种资源，这其中就包括请求本地或者外部服务器的压缩文件。而由于zip格式压缩文件允许”../
      
    
    </summary>
    
      <category term="漏洞研究" scheme="http://yoursite.com/categories/%E6%BC%8F%E6%B4%9E%E7%A0%94%E7%A9%B6/"/>
    
    
      <category term="Android" scheme="http://yoursite.com/tags/Android/"/>
    
      <category term="渗透测试" scheme="http://yoursite.com/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
      <category term="ZipEntry" scheme="http://yoursite.com/tags/ZipEntry/"/>
    
  </entry>
  
  <entry>
    <title>伪全栈式安全研发：CVE监控</title>
    <link href="http://yoursite.com/2017/09/02/%E4%BC%AA%E5%85%A8%E6%A0%88%E5%BC%8F%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91%EF%BC%9ACVE%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2017/09/02/伪全栈式安全研发：CVE监控/</id>
    <published>2017-09-02T13:57:52.000Z</published>
    <updated>2017-09-25T03:23:05.237Z</updated>
    
    <content type="html"><![CDATA[<h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><p>在网络安全圈，攻防是核心，在攻防中漏洞的重要性不言而喻，而CVE是全世界通用漏洞的集合，对于安全人员来说及时知晓刚爆出的通用型漏洞对于企业来讲是十分必要的。本文讲解上周本人在完成CVE监控研发的过程中的一些技术探讨，为什么叫伪全栈呢，因为全栈远不止前端+后端。本例主要使用的技术为Golang、Vuejs、Mongodb、Beego等。</p><a id="more"></a><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>具体需求为，实时爬取与【公司内部使用的开源框架/组件】相关的业内最新的CVE漏洞，进行网页展示以及报警。</p><h2 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h2><p>由于Mongodb的灵活性与类Json形式的语法，将其作为我们的数据库。根据需求我们需要两个表，一个表存储CVE关键字和其重要程度；另一个表存储具体爬下来的每一个条CVE详情。<br>关键字表数据格式如下（以两条信息为例）：</p><pre><code>{&quot;_id&quot; : ObjectId(&quot;599d2c1ca9218e4e8ec4e6xx&quot;),&quot;keyword&quot; : [     {        &quot;wordname&quot; : &quot;spring&quot;,        &quot;wordcount&quot; : 1    },     {        &quot;wordname&quot; : &quot;java&quot;,        &quot;wordcount&quot; : 2    }}</code></pre><p>其中wordcount为1表示高危，wordcount为2表示中危。<br>CVE详情表数据格式如下(以一条信息为例)：</p><pre><code>{&quot;_id&quot; : ObjectId(&quot;59a69bf70988ac81605b76xx&quot;),&quot;cve&quot; : &quot;CVE-2017-13758&quot;,&quot;keyword&quot; : &quot;ImageMagick&quot;,&quot;note&quot; : &quot;In ImageMagick 7.0.6-10, there is a heap-based buffer overflow in theTracePoint() function in MagickCore/draw.c.&quot;,&quot;time&quot; : &quot;2017-08-30 19:05:28&quot;,&quot;references&quot; : &quot;CONFIRM:https://www.imagemagick.org/discourse-server/viewtopic.php?f=3&amp;amp;t=32583&quot;,&quot;isignored&quot; : true}</code></pre><p>需要注意的是isignored字段表示是否需要忽略，在安全人员查看信息时，如果认为当前条目CVE不存在严重影响，甚至可以忽略时可以将其置为忽略，而本字段记录其状态。</p><h2 id="爬虫的研发"><a href="#爬虫的研发" class="headerlink" title="爬虫的研发"></a>爬虫的研发</h2><p>我们首先需要找到需要爬取的信息源，一方面需要一个接口能告知我们每日的更新，另一方面我们需要知晓每个CVE编号对应的漏洞详情。通过CVE官网<a href="http://cve.mitre.org/，我们很快找到了两个需要的接口：" target="_blank" rel="external">http://cve.mitre.org/，我们很快找到了两个需要的接口：</a></p><pre><code>https://cassandra.cerias.purdue.edu/CVE_changes/today.html</code></pre><p>以及</p><pre><code>http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-xxxx-xxxx</code></pre><p>姑且称他们为接口1和接口2.爬虫的整体逻辑为向接口1发送请求，正则匹配出我们需要的【New entries】信息，如下图所示<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-02_23-17-20.png" alt=""><br>然后分别爬取每个cve对应的接口2的url，继续正则匹配出我们想要的漏洞详情信息、相关文档信息等，我们需要的信息如下。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-02_23-29-52.png" alt=""><br>随后查keyword库判断是否为我们想要的漏洞，这里比较的是keyword与Description信息，如果是则存到库中。<br>回看整个过程，略微存在技术难点的地方在于正则表达式的编写与golang对Mongodb数据库的操作。<br>请求到的页面源码中，CVE编号的存在形式如下：</p><pre><code>&lt;A HREF = &apos;http://cve.mitre.org/cgi-bin/cvename.cgi?name=2017-3898&apos;&gt;2017-3898&lt;/A&gt;&lt;br /&gt;</code></pre><p>发送请求利用的是grequests库，爬取每日CVE更新信息代码如下：</p><pre><code>func monitorCVEimpl() ([]string) {op := grequests.RequestOptions{    RequestTimeout:     10 * time.Second,    InsecureSkipVerify: true,    RedirectLimit:      5,}urlStr := &quot;https://cassandra.cerias.purdue.edu/CVE_changes/today.html&quot;res, _ := grequests.Get(urlStr, &amp;op)newEntriesStr := Between(res.String(), &quot;New entries:&lt;br /&gt;&quot;, &quot;Graduations (CAN to CVE)&quot;)digitsRegexp := regexp.MustCompile(&quot;&lt;A HREF = &apos;(.*?)&apos;&gt;(.*?)&lt;/A&gt;&quot;)data := digitsRegexp.FindAllStringSubmatch(newEntriesStr, -1)cveStrList := []string{}for _, v := range data {    //fmt.Println(v[2])    if v[2] != &quot;&quot; {        cveStrList = append(cveStrList, v[2])    }}return cveStrList}</code></pre><p>其中Between函数为一个工具函数，获取一个字符串中在字符串2和字符串3中间的子字符串。</p><pre><code>func Between(str, starting, ending string) string {s := strings.Index(str, starting)if s &lt; 0 {    return &quot;&quot;}s += len(starting)e := strings.Index(str[s:], ending)if e &lt; 0 {    return &quot;&quot;}return str[s: s+e]}</code></pre><p><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-02_23-49-48.png" alt=""><br>最终返回类似[‘2017-10848’,’2017-10849’]的字符串切片。<br>随后构造为接口2模式的url，同样的方式进行请求，通过工具函数和regexp包，我们能够获取到页面存在的我们需要的信息。随后进行入库操作，Golang操作Mongodb用的是mgo包，基本的增删改查语法可以在<a href="https://studygolang.com/articles/1737查阅到，需要注意的是我们经常会遇到模糊查询的情况，遇到模糊查询时，可以用下面的解决办法：" target="_blank" rel="external">https://studygolang.com/articles/1737查阅到，需要注意的是我们经常会遇到模糊查询的情况，遇到模糊查询时，可以用下面的解决办法：</a></p><pre><code>err := mCVEdb.Find(bson.M{&quot;cve&quot;: bson.M{&quot;$regex&quot;: &quot;CVE-2017&quot;, &quot;$options&quot;: &quot;$i&quot;}}).Distinct(&quot;cve&quot;,&amp;res)</code></pre><p>查询数据库对象mCVEdb对应的数据库中，cve字段模糊匹配CVE-2017字样的文档，并且结果只返回cve集合。<br>根据bson.go官方包中的规定,options参数设置为i是不分大小写的匹配，正好符合我们的需求。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-03_00-11-01.png" alt=""><br>至此，我们成功的写完了爬虫脚本并且执行后能把数据存入我们的库中。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-03_00-17-38.png" alt=""></p><h2 id="界面的展现"><a href="#界面的展现" class="headerlink" title="界面的展现"></a>界面的展现</h2><p>我们需要一个可视化平台，能够看到我们爬取到的CVE数据。搭建这个平台需要后端接口研发以及前端页面的展现。我们使用的golang http框架为beego，支持RESTful API和MVC模型。<br>后端接口的研发：<br>后端接口，主要是用来查询数据库中的数据并且以json格式返回。<br>在Controller文件中写入</p><pre><code>// @router /cve/ [get]func (c *CveController) GetAll() {var mResultCve = new(models.CveResult)result, err := mResultCve.Cve_search_today()if err != nil {    c.Data[&quot;json&quot;] = utils.AjaxReturn(result, &quot;get message success&quot;, 1)}else {    c.Data[&quot;json&quot;] = utils.AjaxReturn(&quot;&quot;, &quot;Error&quot;, -1)}c.ServeJSON()}</code></pre><p>models层中定义Cve_search_today()函数，将来我们可以在<a href="http://localhost:8080/cve接口获取到返回的json数据以供前端调用。" target="_blank" rel="external">http://localhost:8080/cve接口获取到返回的json数据以供前端调用。</a><br>Cve_search_today()函数模糊查询time字段为当天的数据即可，将[]CVEinfo和err一同返回。<br>前端页面的研发：<br>首先我们需要一个页面url，在Controller中指定：</p><pre><code>//@router /Cve [get]func (this *CveController) GetPage() {this.Data[&quot;title&quot;] = &quot;CVE信息 - &quot;//导航的IDthis.Data[&quot;navCode&quot;] = &quot;opinionNavCode&quot;this.TplName = &quot;cveInfo/index.html&quot;}</code></pre><p>随后编写cveInfo/index.html文件，利用layui+Vuejs进行开发<br>js主要代码</p><pre><code>var vm = new Vue({        delimiters: [&apos;[[&apos;, &apos;]]&apos;],        el: &quot;#body_id&quot;,        data: {            url: &quot;&quot;,            cveList: [],            cveNum: 0,            lasttime: &quot;&quot;,            cveTasktime: &quot;&quot;,            date_range_list: &quot;&quot;            //testList: [&quot;test1&quot;, &quot;test2&quot;, &quot;test3&quot;, &quot;test4&quot;]        },        methods: {            loadData: function (ev) {                var _cveurl = &quot;/cve&quot;                this.cveInfoUrl(_cveurl);                this.cveTaskInfo();            },            initLoad: function () {                var e = {&quot;keyCode&quot;: 13};                this.loadData(e);            },            cveInfoUrl: function (url) {                var me = this;                $.ajax({                    async: true,                    url: url,                    type: &apos;get&apos;,                    datatype: &apos;json&apos;,                    success: function (data) {                        me.buildData(data, me)                    }                });            },            cveTaskInfo: function () {                var me = this;                $.ajax({                    async: true,                    url: &quot;/CveTaskTime&quot;,                    type: &apos;get&apos;,                    datatype: &apos;json&apos;,                    success: function (data) {                        me.lasttime = data.data;                    }                });            },            buildData: function (data, me) {                $(&apos;#cve_id&apos;).html(&quot;&lt;center style=&apos;margin-top:100px&apos;&gt;&lt;a  class=&apos;layui-btn layui-btn-disabled&apos;&gt;数据加载中...&lt;/a&gt;&lt;/center&gt;&quot;);                if (data.status == -1 || data.status == -5) {                    $(&apos;#cve_id&apos;).html(&quot;&lt;center style=&apos;margin-top:100px&apos;&gt;&lt;a  class=&apos;layui-btn layui-btn-disabled&apos;&gt;暂无cve信息&lt;/a&gt;&lt;/center&gt;&quot;);                    return false;                } else {                    $(&apos;#cve_id&apos;).html(&quot;&quot;);                }                var _tmpList = data.data.CveList;                console.log(data.data.CveNum);                this.cveList = []                this.cveNum = data.data.CveNum;                for (var d in _tmpList) {                    if (_tmpList[d].Isignored == false) {                        me.cveList.push({                            &quot;cve&quot;: _tmpList[d].Cve,                            &quot;keyword&quot;: _tmpList[d].Keyword,                            &quot;note&quot;: _tmpList[d].Note,                            &quot;time&quot;: _tmpList[d].Time,                            &quot;reference&quot;: _tmpList[d].References,                            &quot;isignored&quot;: _tmpList[d].Isignored                        });                    }                }                for (var d in _tmpList) {                    if (_tmpList[d].Isignored == true) {                        me.cveList.push({                            &quot;cve&quot;: _tmpList[d].Cve,                            &quot;keyword&quot;: _tmpList[d].Keyword,                            &quot;note&quot;: _tmpList[d].Note,                            &quot;time&quot;: _tmpList[d].Time,                            &quot;reference&quot;: _tmpList[d].References,                            &quot;isignored&quot;: _tmpList[d].Isignored                        });                    }                }                console.log(me.cveList);            },            ignore: function (message) {                $.get(&apos;/cveIgnore/&apos; + message, &apos;&apos;, function (data, status) {                    vm.buildData(data, vm)                })            },            unignore: function (message) {                $.get(&apos;/cveUnIgnore/&apos; + message, &apos;&apos;, function (data, status) {                    vm.buildData(data, vm)                })            }        }    });    //加载事件    window.onload = function () {        vm.initLoad();    };</code></pre><p>html部分主要利用v-for循环和v-if判断来读取ajax请求返回的内容，[[]]双括号可以将vuejs处理后的data数据返回到html页面。<br>页面效果如图：<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-03_00-43-26.png" alt=""><br>因为让页面更加简洁优美所以未将CVE漏洞详情信息放入页面。</p><h2 id="定时与实时"><a href="#定时与实时" class="headerlink" title="定时与实时"></a>定时与实时</h2><p>要能够定时地完成爬取，我们就需要利用beego的Task任务模块。将开始我们编写的爬虫脚本挂载到beego框架中，然后在脚本最后加入</p><pre><code>func CveRun() {cveSpiderRun := toolbox.NewTask(&quot;cve_spider_run&quot;, &quot;0 0 7 * * *&quot;, CveSpider)toolbox.AddTask(&quot;cve_spider_run&quot;, cveSpiderRun)toolbox.StartTask()defer toolbox.StopTask()}</code></pre><p>需要注意的是toolbox.AddTask第二个参数是脚本启动的入口函数，0 0 7 <em> </em> *为定时任务的时间设定，再此为每日的7点，我们也可以自定义设置，比如每隔10分钟等等，语法与Linux中的Crontab类似。<br>随后在beego Controller层的DefaultController中加入</p><pre><code>func init() {//初始化CVE任务cveTask.CveRun()}</code></pre><p>即可。<br>再此启动项目，访问8088端口(默认)，在Task中可以管理任务。<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-03_00-51-46.png" alt=""></p><h2 id="邮件预警"><a href="#邮件预警" class="headerlink" title="邮件预警"></a>邮件预警</h2><p>在爬虫文件入库后加入邮件预警函数，内容也较为简单，调用github.com/go-gomail/gomail库发送html邮件，主要代码为先gomail.NewMessage()创建新的Message对象，然后设置邮箱正文、头信息等，使用gomail.NewPlainDialer()配置本端邮箱的账号密码stmp信息，最后DialAndSend()发送即可，注意对异常的处理。邮件正文如下<br><img src="http://ovnsp3bhk.bkt.clouddn.com/Snipaste_2017-09-03_00-54-31.png" alt=""></p><h2 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>本项目仍可提高的点我认为有如下：<br>1.利用Golang并发编程机制加快爬虫速度<br>2.Web界面与邮件界面的UI更加优雅<br>3.多维度漏洞爬虫<br>感谢@Dean、@Mr.Hao、@tanglion在研发过程中对我的帮助与启发。<br>如有错误还请帮指出，感谢阅读。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;主题&quot;&gt;&lt;a href=&quot;#主题&quot; class=&quot;headerlink&quot; title=&quot;主题&quot;&gt;&lt;/a&gt;主题&lt;/h2&gt;&lt;p&gt;在网络安全圈，攻防是核心，在攻防中漏洞的重要性不言而喻，而CVE是全世界通用漏洞的集合，对于安全人员来说及时知晓刚爆出的通用型漏洞对于企业来讲是十分必要的。本文讲解上周本人在完成CVE监控研发的过程中的一些技术探讨，为什么叫伪全栈呢，因为全栈远不止前端+后端。本例主要使用的技术为Golang、Vuejs、Mongodb、Beego等。&lt;/p&gt;
    
    </summary>
    
      <category term="安全研发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/"/>
    
    
      <category term="Golang" scheme="http://yoursite.com/tags/Golang/"/>
    
      <category term="Vuejs" scheme="http://yoursite.com/tags/Vuejs/"/>
    
      <category term="Mongodb" scheme="http://yoursite.com/tags/Mongodb/"/>
    
      <category term="Beego" scheme="http://yoursite.com/tags/Beego/"/>
    
  </entry>
  
  <entry>
    <title>python 基于nmap多线程扫描ms17-010脚本</title>
    <link href="http://yoursite.com/2017/08/26/python-%E5%9F%BA%E4%BA%8Enmap%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%89%AB%E6%8F%8Fms17-010%E8%84%9A%E6%9C%AC/"/>
    <id>http://yoursite.com/2017/08/26/python-基于nmap多线程扫描ms17-010脚本/</id>
    <published>2017-08-26T11:31:03.000Z</published>
    <updated>2017-09-25T03:13:28.059Z</updated>
    
    <content type="html"><![CDATA[<h2 id="详情"><a href="#详情" class="headerlink" title="详情"></a>详情</h2><p>nmap 7.50及以后的版本支持对MS17-010漏洞，即永恒之蓝漏洞的扫描，以下为针对甲方公司的安全人员，针对公司内网网段进行批量的多线程漏洞扫描。</p><p>脚本的原理为首先生成一个带扫描的ip文件，然后调用nmap命令nmap -iL ip_test.txt -p 445 –open -T4 -oX ./result/filename.txt来扫描开放了445端口的ip，并生成列表，随后读取445端口开放的ip并放入队列中，然后多线程处理队列中的ip并利用nmap命令nmap -p 445 –script smb-vuln-ms17-010.nse IP来检测存在漏洞的ip数量。</p><a id="more"></a><p>nmap 7.50及以后的版本支持对MS17-010漏洞，即永恒之蓝漏洞的扫描，以下为针对甲方公司的安全人员，针对公司内网网段进行批量的多线程漏洞扫描。</p><p>脚本的原理为首先生成一个带扫描的ip文件，然后调用nmap命令nmap -iL ip_test.txt -p 445 –open -T4 -oX ./result/filename.txt来扫描开放了445端口的ip，并生成列表，随后读取445端口开放的ip并放入队列中，然后多线程处理队列中的ip并利用nmap命令nmap -p 445 –script smb-vuln-ms17-010.nse IP来检测存在漏洞的ip数量。</p><pre><code>#!/usr//bin/python# -*- coding: utf-8 -*-# author: bipabo1l@csoio.comimport osimport requestsimport timeimport reimport commandslist_vul_ip = []class WyWorker(threading.Thread):    def __init__(self, queue):        threading.Thread.__init__(self)        self.queue = queue    def run(self):        while True:            if self.queue.empty():                break            try:                ip = self.queue.get_nowait()                if ip:                    (status, output) = commands.getstatusoutput(&apos;nmap -p 445 --script smb-vuln-ms17-010.nse &apos; + ip)                    print output                    if &apos;CVE&apos; in output:                        list_vul_ip.append(ip)            except Exception, e:                break        print &quot;scan success&quot;def main():    try:        threads_count = 10        queue = Queue.Queue()        print &quot;begin:&quot;        files = &apos;445_open:&apos; + str(int(time.time()))        print &quot;scaning:&quot;        os.system(&apos;nmap -iL ip_test.txt -p 445 --open -T4 -oX ./result/%s.txt&apos; % files)        print &quot;scansuccess&quot;        file_name = files + &apos;.txt&apos;        file = open(&apos;/root/619/445/result/%s&apos; % file_name)        f_result = file.read()        regex = &apos;addr(.*)addrtype&apos;        list_ip = []        for m in re.findall(regex, f_result):            list_ip.append(m[10:-2])        print &quot;445 port open mechines:&quot;         print list_ip        for ip in list_ip:            queue.put(ip)        print queue.qsize()        # 初始化线程组        threads = []        for i in xrange(threads_count):            threads.append(WyWorker(queue))        # 启动线程        for t in threads:            t.start()        # 等待线程执行结束后，回到主线程中        for t in threads:            t.join()        print list_vul_ip    except:        passif __name__ == &apos;__main__&apos;:    main()</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;详情&quot;&gt;&lt;a href=&quot;#详情&quot; class=&quot;headerlink&quot; title=&quot;详情&quot;&gt;&lt;/a&gt;详情&lt;/h2&gt;&lt;p&gt;nmap 7.50及以后的版本支持对MS17-010漏洞，即永恒之蓝漏洞的扫描，以下为针对甲方公司的安全人员，针对公司内网网段进行批量的多线程漏洞扫描。&lt;/p&gt;
&lt;p&gt;脚本的原理为首先生成一个带扫描的ip文件，然后调用nmap命令nmap -iL ip_test.txt -p 445 –open -T4 -oX ./result/filename.txt来扫描开放了445端口的ip，并生成列表，随后读取445端口开放的ip并放入队列中，然后多线程处理队列中的ip并利用nmap命令nmap -p 445 –script smb-vuln-ms17-010.nse IP来检测存在漏洞的ip数量。&lt;/p&gt;
    
    </summary>
    
      <category term="安全研发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="MS17-010" scheme="http://yoursite.com/tags/MS17-010/"/>
    
      <category term="wannaCry" scheme="http://yoursite.com/tags/wannaCry/"/>
    
  </entry>
  
  <entry>
    <title>whatweb入库乱码问题详解</title>
    <link href="http://yoursite.com/2017/08/21/whatweb%E5%85%A5%E5%BA%93%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2017/08/21/whatweb入库乱码问题详解/</id>
    <published>2017-08-21T08:24:23.000Z</published>
    <updated>2017-09-25T03:26:46.429Z</updated>
    
    <content type="html"><![CDATA[<p>本文讲解笔者在使用whatweb对域名库中的域名进行指纹爬取并入库mongodb时遇到的一些坑以及解决方案。</p><h2 id="详情"><a href="#详情" class="headerlink" title="详情"></a>详情</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>通过whatweb扫描出来的数据，插入到数据库中后，发现很多不同的编码和乱码，包括url编码、unicode编码、乱码等等，如下</p><a id="more"></a><p><img src="http://i.imgur.com/U3VSDzA.jpg" alt=""></p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>当我直接在命令行执行几个数据库中Title字段乱码或者编码有问题的Domain时，命令行直接输出的Title是正常的中文汉字<br><img src="http://i.imgur.com/exLX3nS.jpg" alt=""><br>所以判断是代码的问题，进入到代码中，发现原来的代码whatweb扫描出来之后，未特殊判断可能带有汉字的Title，于是加上了一个单独的Title判断，如果是Title，那么Append到list之前经过一个函数处理，<br>函数判断是否为unicode（基本全部是unicode），如果是先url解码（因为当前的数据类型是）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">u&apos;JIMI%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA - %E4%BA%AC%E4%B8%9C&apos;</div></pre></td></tr></table></figure></p><!--more--><p>想到把<br><img src="http://i.imgur.com/c7Zwvb8.png" alt=""><br>这段代码直接unicode转汉字应该就能解决问题了，于是加上</p><pre><code>.decode(&apos;unicode-escape&apos;)</code></pre><p>发现直接输出为乱码，return后输出的并未unicode解密，反而二次unicode加密</p><p>于是思考从url解码之前就处理问题，而不是经过解码之后变成unicode再处理。发现在main函数中，最后输出时还有json.dumps处理，那么直接打印处理前的数据，看中文是如何显示的<br><img src="http://i.imgur.com/47SAyJB.png" alt=""><br>发现是控制台信息输出窗口按照ascii编码输出utf8编码的字符串的结果，这时候基本可以定位问题了，是在转换到json格式时出现的问题，json.dumps函数中加一个ensure_ascii参数，值设置为False即可。测试一下：<br><img src="http://i.imgur.com/qOemh19.png" alt=""><br>显示成功！</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>所以最后的解决方案为：<br>1.jdradar\core\fingerprint路径下的WhatWeb.py，parse_plugin函数中判断一下name是否为Title，如果是，将plugin.get(‘string’)处理成字符串模式后，plugins.append({name: deal_word_method(string)})plugins列表添加时string用deal_word_method函数处理，函数判断传入的word是否为unicode，是的话url解码。<br>然后返回<br><img src="http://i.imgur.com/2y69CFG.png" alt=""><br>2.在jdradar\tasks.py的fingerprint_scan函数中，加入json.dumps处理，ensure_ascii设置为False</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>测试是否有效：<br>选取一个原来差入后Title乱码的document，domain为<a href="http://jimi-api.jd.com:80" target="_blank" rel="external">http://jimi-api.jd.com:80</a><br><img src="http://i.imgur.com/emPA8cm.png" alt=""><br>利用如下代码，进行插入<br><img src="http://i.imgur.com/kih39mN.png" alt=""><br>插入成功后，查看DocumentTitle字段是否乱码<br><img src="http://i.imgur.com/iJJO6Pi.png" alt=""><br>执行成功，未乱码</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文讲解笔者在使用whatweb对域名库中的域名进行指纹爬取并入库mongodb时遇到的一些坑以及解决方案。&lt;/p&gt;
&lt;h2 id=&quot;详情&quot;&gt;&lt;a href=&quot;#详情&quot; class=&quot;headerlink&quot; title=&quot;详情&quot;&gt;&lt;/a&gt;详情&lt;/h2&gt;&lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;通过whatweb扫描出来的数据，插入到数据库中后，发现很多不同的编码和乱码，包括url编码、unicode编码、乱码等等，如下&lt;/p&gt;
    
    </summary>
    
      <category term="安全研发" scheme="http://yoursite.com/categories/%E5%AE%89%E5%85%A8%E7%A0%94%E5%8F%91/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
</feed>
